<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Neural Networks Fundamentals | Deep Learning Specialist</title>
    
    <!-- Font imports -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;500;700&family=Fira+Code&display=swap" rel="stylesheet">
    
    <!-- Styles -->
    <link rel="stylesheet" href="/assets/css/style.css">
    <link rel="stylesheet" href="/assets/css/module.css">

    <!-- Code highlighting -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/atom-one-dark.min.css">
</head>
<body>
    <!-- Progress Bar -->
    <div class="progress-indicator">
        <div class="progress-bar" style="width: 0%"></div>
    </div>

    <main class="module-content">
        <!-- Module Header -->
        <section class="module-header">
            <h1>Neural Networks Fundamentals</h1>
            <p class="module-description">Master the foundational concepts of neural networks, including network architecture, activation functions, forward propagation, and the basics of training neural networks.</p>
        </section>

        <!-- Neural Network Architecture Section -->
        <section class="concept-section">
            <h2>Neural Network Architecture</h2>
            
            <div class="concept-explanation">
                <h3>The Core Idea</h3>
                <p>A neural network is composed of layers of interconnected nodes (neurons) that process and transform information. The basic structure includes an input layer, one or more hidden layers, and an output layer, with each neuron connected to neurons in adjacent layers.</p>
            </div>

            <div class="metaphor-box">
                <h3>The Corporate Hierarchy</h3>
                <p>Think of a neural network like a company's organizational structure. Information flows from entry-level employees (input layer) through various departments (hidden layers) to executives (output layer). Each employee (neuron) processes information and passes it to the next level, with the strength of connections representing how much influence each piece of information has.</p>
                <ul>
                    <li>Entry-level employees represent input neurons receiving raw data</li>
                    <li>Department managers represent hidden layer neurons processing information</li>
                    <li>Executives represent output neurons making final decisions</li>
                    <li>Communication channels represent weights between neurons</li>
                </ul>
            </div>

            <div class="technical-example">
                <h3>Technical Implementation</h3>
                <pre><code class="python">import torch
import torch.nn as nn

class SimpleNeuralNetwork(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(SimpleNeuralNetwork, self).__init__()
        # First layer (input -> hidden)
        self.layer1 = nn.Linear(input_size, hidden_size)
        # Second layer (hidden -> output)
        self.layer2 = nn.Linear(hidden_size, output_size)
        
    def forward(self, x):
        # Forward pass through the network
        hidden = self.layer1(x)
        output = self.layer2(hidden)
        return output

# Create a network with 2 inputs, 3 hidden neurons, and 1 output
model = SimpleNeuralNetwork(input_size=2, hidden_size=3, output_size=1)</code></pre>
            </div>

            <div class="concept-quiz">
                <h3>Quick Check</h3>
                <div class="quiz-question">
                    <p>What is the primary purpose of hidden layers in a neural network?</p>
                    <form>
                        <label>
                            <input type="radio" name="q1" value="a">
                            To store the input data
                        </label>
                        <label>
                            <input type="radio" name="q1" value="b">
                            To transform and extract features from the data
                        </label>
                        <label>
                            <input type="radio" name="q1" value="c">
                            To save memory during computation
                        </label>
                        <label>
                            <input type="radio" name="q1" value="d">
                            To speed up the training process
                        </label>
                    </form>
                </div>
            </div>
        </section>

        <!-- Activation Functions Section -->
        <section class="concept-section">
            <h2>Activation Functions</h2>
            
            <div class="concept-explanation">
                <h3>The Core Idea</h3>
                <p>Activation functions introduce non-linearity into neural networks, allowing them to learn complex patterns. They determine whether and to what extent a neuron should be activated, transforming the input signal into an output signal.</p>
            </div>

            <div class="metaphor-box">
                <h3>The Office Worker's Decision Threshold</h3>
                <p>Think of activation functions like an office worker deciding whether to escalate information to their supervisor. Different workers might use different criteria (activation functions) - some might use a simple yes/no threshold (step function), others might grade the importance on a scale (sigmoid), and some might pass along information more freely while filtering out only the clearly irrelevant (ReLU).</p>
                <ul>
                    <li>Step function is like a strict yes/no decision</li>
                    <li>Sigmoid is like rating importance from 0 to 1</li>
                    <li>ReLU is like ignoring negative feedback and passing positive feedback unchanged</li>
                    <li>Different functions suit different types of decisions</li>
                </ul>
            </div>

            <div class="technical-example">
                <h3>Technical Implementation</h3>
                <pre><code class="python">import torch
import torch.nn as nn
import torch.nn.functional as F

class ActivationExamples(nn.Module):
    def __init__(self):
        super(ActivationExamples, self).__init__()
    
    def forward(self, x):
        # ReLU activation
        relu_output = F.relu(x)
        
        # Sigmoid activation
        sigmoid_output = torch.sigmoid(x)
        
        # Tanh activation
        tanh_output = torch.tanh(x)
        
        # Leaky ReLU
        leaky_relu_output = F.leaky_relu(x, negative_slope=0.01)
        
        return {
            'relu': relu_output,
            'sigmoid': sigmoid_output,
            'tanh': tanh_output,
            'leaky_relu': leaky_relu_output
        }</code></pre>
            </div>

            <div class="concept-quiz">
                <h3>Quick Check</h3>
                <div class="quiz-question">
                    <p>Why is ReLU (Rectified Linear Unit) commonly used in modern neural networks?</p>
                    <form>
                        <label>
                            <input type="radio" name="q2" value="a">
                            It's the most mathematically complex activation function
                        </label>
                        <label>
                            <input type="radio" name="q2" value="b">
                            It helps prevent the vanishing gradient problem and is computationally efficient
                        </label>
                        <label>
                            <input type="radio" name="q2" value="c">
                            It always outputs values between 0 and 1
                        </label>
                        <label>
                            <input type="radio" name="q2" value="d">
                            It's the only differentiable activation function
                        </label>
                    </form>
                </div>
            </div>
        </section>

        <!-- Forward Propagation Section -->
        <section class="concept-section">
            <h2>Forward Propagation</h2>
            
            <div class="concept-explanation">
                <h3>The Core Idea</h3>
                <p>Forward propagation is the process of passing input data through a neural network to generate predictions. Each layer applies weights, biases, and activation functions to transform the data, with information flowing from input to output.</p>
            </div>

            <div class="metaphor-box">
                <h3>The Assembly Line</h3>
                <p>Think of forward propagation like an assembly line in a factory. Raw materials (input data) enter the line and pass through various workstations (layers). At each station, workers (neurons) perform specific operations (weights and activations) on the materials, gradually transforming them into the final product (output).</p>
                <ul>
                    <li>Raw materials represent input data</li>
                    <li>Workstations represent network layers</li>
                    <li>Worker operations represent weights and activations</li>
                    <li>Final product represents the network's prediction</li>
                </ul>
            </div>

            <div class="technical-example">
                <h3>Technical Implementation</h3>
                <pre><code class="python">import torch
import torch.nn as nn

class ForwardPropExample(nn.Module):
    def __init__(self):
        super(ForwardPropExample, self).__init__()
        self.layer1 = nn.Linear(2, 3)
        self.layer2 = nn.Linear(3, 1)
        self.relu = nn.ReLU()
        
    def forward(self, x):
        # First layer transformation
        z1 = self.layer1(x)
        # First layer activation
        a1 = self.relu(z1)
        
        # Second layer transformation
        z2 = self.layer2(a1)
        # Final output
        output = torch.sigmoid(z2)
        
        return output

# Example usage
model = ForwardPropExample()
input_data = torch.tensor([[0.5, 0.8]])
prediction = model(input_data)</code></pre>
            </div>

            <div class="concept-quiz">
                <h3>Quick Check</h3>
                <div class="quiz-question">
                    <p>What happens during forward propagation?</p>
                    <form>
                        <label>
                            <input type="radio" name="q3" value="a">
                            The network updates its weights
                        </label>
                        <label>
                            <input type="radio" name="q3" value="b">
                            The network processes input data layer by layer to produce an output
                        </label>
                        <label>
                            <input type="radio" name="q3" value="c">
                            The network calculates error gradients
                        </label>
                        <label>
                            <input type="radio" name="q3" value="d">
                            The network optimizes its parameters
                        </label>
                    </form>
                </div>
            </div>
        </section>

        <!-- Module Summary -->
        <section class="module-summary">
            <h2>Key Takeaways</h2>
            <ul>
                <li>Neural networks are composed of layers of interconnected neurons that process and transform information</li>
                <li>Activation functions introduce non-linearity, allowing networks to learn complex patterns</li>
                <li>Forward propagation is the process of passing data through the network to generate predictions</li>
                <li>Different activation functions serve different purposes and have unique characteristics</li>
            </ul>
        </section>

        <!-- Navigation -->
        <section class="module-navigation">
            <button class="btn btn-primary next-module" data-module="dls-002">Continue to Next Module</button>
            <button class="btn btn-secondary save-progress">Save Progress</button>
        </section>
    </main>

    <!-- Module Data -->
    <script>
    const moduleData = {
        id: "dls-001",
        path: "deep-learning-specialist",
        progress: 0
    };
    </script>

    <!-- Scripts -->
    <script src="/assets/js/module.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
</body>
</html>
